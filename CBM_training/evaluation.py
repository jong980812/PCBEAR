import argparse
import sys
from datetime import datetime
import os
import json
import torch
import os
import random
import cbm
import plots
import random
import numpy as np
from video_dataloader import video_utils
import train_video_cbm
from video_dataloader import datasets
import cbm_utils

def load_all_concepts_by_type(load_dir, train_mode):
    concept_dict = {}
    for concept_type in train_mode:
        concept_path = os.path.join(load_dir, concept_type, "concepts.txt")
        if not os.path.exists(concept_path):
            print(f"âš ï¸ Warning: concepts.txt not found for {concept_type}")
            continue
        with open(concept_path, 'r') as f:
            concepts = f.read().splitlines()
        concept_dict[concept_type] = concepts
    return concept_dict


parser = argparse.ArgumentParser(description='Evaluatin ours')
parser.add_argument('--load_dir',required=True,type=str, default='', help='Trained model path')
parser.add_argument('--batch_size',type=int, default=32, help='Inference batch size')
parser.add_argument('--subset_labels', nargs='*', default=None, help='List of class labels to evaluate subset metrics')
def main(train_args, test_args):
    # video_utils.init_distributed_mode(test_args)
    train_video_cbm.setup_seed(train_args.seed)
    # save_dir = test_args.load_dir #! ê°™ì€ í´ë”ì— ì €ì¥
    device = "cuda" if torch.cuda.is_available() else 'cpu'
    load_dir=test_args.load_dir
    
    import numpy as np

    inference_dir = os.path.join(load_dir, "inference")
    os.makedirs(inference_dir, exist_ok=True)

    # ì²´í¬í¬ì¸íŠ¸ê°€ ì¡´ì¬í•˜ë©´ load
    preds_path = os.path.join(inference_dir, "preds.npy")
    labels_path = os.path.join(inference_dir, "labels.npy")
    report_path = os.path.join(inference_dir, "report.txt")
    class_acc_path = os.path.join(inference_dir, "class_acc.txt")
    model = cbm.load_cbm_dynamic(load_dir, device,train_args)
    cls_file = os.path.join(train_args.video_anno_path, 'class_list.txt')
    with open(cls_file, "r") as f:
        class_names = f.read().split("\n")
    if os.path.exists(preds_path) and os.path.exists(labels_path) and os.path.exists(report_path):
        print("âœ… Loading cached inference results...")
        all_preds = np.load(preds_path)
        all_labels = np.load(labels_path)
        with open(report_path, "r") as f:
            report = f.read()
    else:
        # inference ìˆ˜í–‰
        val_video_dataset,_ =   datasets.build_dataset(False, False, train_args)
        # accuracy = cbm_utils.get_accuracy_cbm(model, val_video_dataset, device,test_args.batch_size,8)
        report, cm, all_labels, all_preds,class_acc = cbm_utils.get_detailed_metrics_cbm(model, val_video_dataset, device, batch_size=test_args.batch_size, class_names=class_names,return_raw=True)
            # ì €ì¥
        with open(class_acc_path, "w") as f:
            for class_name, acc in sorted(class_acc.items(), key=lambda x: x[1], reverse=True):
                f.write(f"{class_name}: {acc:.4f}\n")
        print(f"âœ… í´ë˜ìŠ¤ë³„ accuracy ì €ì¥ ì™„ë£Œ: {save_path}")
        np.save(preds_path, np.array(all_preds))
        np.save(labels_path, np.array(all_labels))
        with open(report_path, "w") as f:
            f.write(report)
        print("ğŸ“„ Inference ê²°ê³¼ ì €ì¥ ì™„ë£Œ!")
    
    


    # COncept ì •ë³´ print
    concept_dict = load_all_concepts_by_type(load_dir, train_args.train_mode)
    if len(train_args.train_mode)<2:
        '''
        Singleì˜ ê²½ìš° aggregated ì´ì œ ì•ˆí•˜ê³ , í•´ë‹¹ ì»¨ì…‰ í´ë”ë§Œ ë§Œë“¤ì–´ì§.
        '''
        concepts = concept_dict[train_args.train_mode[0]]
        if 'class_attributes' in train_args.pose_label.split('/')[-1]:
            '''UCF101 class attributesì˜ ê²½ìš° Concpet name ë”°ë¡œ ë¶ˆëŸ¬ì™€ì•¼í•¨. '''
            with open('/data/jongseo/project/PCBEAR/dataset/UCF101/class_attributes/attribute.txt', 'r') as f:
                concepts = f.read().splitlines()
    else:
        ''' train modeê°€ 2ê°œ ì´ìƒì¼ ê²½ìš° aggregatedê°€ ë¬´ì¡°ê±´ ìƒê¸°ê¸°ë•Œë¬¸ì— aggregatedë¡œ. '''
        with open(os.path.join(load_dir, "aggregated", "concepts.txt"), 'r') as f:
            concepts = f.read().splitlines()
    assert len(concepts) ==model.final.weight.shape[1], f"miss"
    print(f"Concept number: {len(concepts)}")


    if test_args.subset_labels:
        result = cbm_utils.get_off_diagonal_confusion_rate(
            all_labels, all_preds, class_names, test_args.subset_labels
        )
        
        # ì €ì¥ ê²½ë¡œ
        save_path = os.path.join(load_dir, f"off_diag_{'+'.join(test_args.subset_labels)}.txt")
        with open(save_path, 'w') as f:
            f.write(f"Target Labels: {result['subset_labels']}\n")
            f.write(f"Total samples: {result['total']}\n")
            f.write(f"Off-diagonal sum: {result['off_diagonal_sum']}\n")
            f.write(f"Confusion rate: {result['confusion_rate']:.4f}\n")
            f.write("Confusion matrix:\n")
            f.write(np.array2string(result['confusion_matrix'], separator=', '))
        print(f"âœ… Saved off-diagonal analysis to {save_path}")
        # If subset labels are given, calculate subset metrics
    if test_args.subset_labels:

        cm, report = cbm_utils.get_class_subset_confusion(all_labels, all_preds, class_names, test_args.subset_labels)
        label_str = '+'.join(test_args.subset_labels)
        # filename = f"confusion_subset_{label_str}.txt"
        report_path=os.path.join(load_dir, f"classification_report_{label_str}.txt")
    else:
        report_path = os.path.join(load_dir, "classification_report.txt")
    with open(report_path, "w") as f:
        f.write(report)
    print(f"ğŸ“„ Saved classification report to {report_path}")
    


if __name__=='__main__':
    test_args = parser.parse_args()
    start_time = datetime.now()
    # ì €ì¥ëœ ê²½ë¡œ
    args_dir = os.path.join(test_args.load_dir, "args.txt")
    # json íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    with open(args_dir, 'r') as f:
        args_dict = json.load(f)

    # dict â†’ argparse.Namespaceë¡œ ë³€í™˜
    train_args = argparse.Namespace(**args_dict)
    
    main(train_args,test_args)
    end_time = datetime.now()
    print(f"ğŸš€ Run time: {(end_time-start_time).total_seconds():.2f} seconds")  # ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
